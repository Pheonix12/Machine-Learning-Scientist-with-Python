{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_objective.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gisandnes/Extreme-Gradient-Boosting-with-XGBoost_DataCamp/blob/master/custom_objective.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VcK__LqJj5_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "42e3630e-ac64-44d2-96ab-ff87cdd6af80"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf ../data\n",
        "!mkdir -p ../data #Make folders for downloads\n",
        "\n",
        "!wget --no-verbose https://raw.githubusercontent.com/gisandnes/xgboost/master/demo/data/agaricus.txt.train -O ../data/agaricus.txt.train\n",
        "!wget --no-verbose https://raw.githubusercontent.com/gisandnes/xgboost/master/demo/data/agaricus.txt.test  -O ../data/agaricus.txt.test"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-03-09 18:09:45 URL:https://raw.githubusercontent.com/gisandnes/xgboost/master/demo/data/agaricus.txt.train [742257/742257] -> \"../data/agaricus.txt.train\" [1]\n",
            "2019-03-09 18:09:47 URL:https://raw.githubusercontent.com/gisandnes/xgboost/master/demo/data/agaricus.txt.test [183611/183611] -> \"../data/agaricus.txt.test\" [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vN7yRV5tjAIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b827389b-99bf-43fa-c561-09336323e68f"
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "###\n",
        "# advanced: customized loss function\n",
        "#\n",
        "print('start running example to used customized objective function')\n",
        "\n",
        "dtrain = xgb.DMatrix('../data/agaricus.txt.train')\n",
        "dtest = xgb.DMatrix('../data/agaricus.txt.test')\n",
        "\n",
        "# note: for customized objective function, we leave objective as default\n",
        "# note: what we are getting is margin value in prediction\n",
        "# you must know what you are doing\n",
        "param = {'max_depth': 2, 'eta': 1, 'silent': 1}\n",
        "#watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
        "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "num_round = 100\n",
        "\n",
        "# user define objective function, given prediction, return gradient and second order gradient\n",
        "# this is log likelihood loss\n",
        "def logregobj(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    preds = 1.0 / (1.0 + np.exp(-preds))\n",
        "    grad = preds - labels\n",
        "    hess = preds * (1.0 - preds)\n",
        "    return grad, hess\n",
        "\n",
        "# user defined evaluation function, return a pair metric_name, result\n",
        "# NOTE: when you do customized loss function, the default prediction value is margin\n",
        "# this may make builtin evaluation metric not function properly\n",
        "# for example, we are doing logistic loss, the prediction is score before logistic transformation\n",
        "# the builtin evaluation error assumes input is after logistic transformation\n",
        "# Take this in mind when you use the customization, and maybe you need write customized evaluation function\n",
        "def evalerror(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    # return a pair metric_name, result. The metric name must not contain a colon (:) or a space\n",
        "    # since preds are margin(before logistic transformation, cutoff at 0)\n",
        "    return 'my-error', float(sum(labels != (preds > 0.0))) / len(labels)\n",
        "\n",
        "# training with customized objective, we can also do step by step training\n",
        "# simply look at xgboost.py's implementation of train\n",
        "\n",
        "#Case 1: obj and feval fit together\n",
        "bst = xgb.train(params=param, dtrain=dtrain, num_boost_round=num_round, evals=watchlist, obj=logregobj, feval=evalerror, early_stopping_rounds=5)\n",
        "print(\"best_score:       \", bst.best_score)\n",
        "print(\"best_iteration:   \", bst.best_iteration)\n",
        "print(\"best_ntree_limit: \", bst.best_ntree_limit)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start running example to used customized objective function\n",
            "[0]\ttrain-rmse:1.59597\teval-rmse:1.59229\ttrain-my-error:0.046522\teval-my-error:0.042831\n",
            "Multiple eval metrics have been passed: 'eval-my-error' will be used for early stopping.\n",
            "\n",
            "Will train until eval-my-error hasn't improved in 5 rounds.\n",
            "[1]\ttrain-rmse:2.40977\teval-rmse:2.40519\ttrain-my-error:0.022263\teval-my-error:0.021726\n",
            "[2]\ttrain-rmse:2.87459\teval-rmse:2.88253\ttrain-my-error:0.007063\teval-my-error:0.006207\n",
            "[3]\ttrain-rmse:3.63621\teval-rmse:3.62808\ttrain-my-error:0.0152\teval-my-error:0.018001\n",
            "[4]\ttrain-rmse:3.83893\teval-rmse:3.80794\ttrain-my-error:0.007063\teval-my-error:0.006207\n",
            "[5]\ttrain-rmse:3.96515\teval-rmse:3.9293\ttrain-my-error:0.001228\teval-my-error:0\n",
            "[6]\ttrain-rmse:4.70775\teval-rmse:4.68611\ttrain-my-error:0.001228\teval-my-error:0\n",
            "[7]\ttrain-rmse:5.6368\teval-rmse:5.6103\ttrain-my-error:0.001228\teval-my-error:0\n",
            "[8]\ttrain-rmse:5.37778\teval-rmse:5.33298\ttrain-my-error:0.001228\teval-my-error:0\n",
            "[9]\ttrain-rmse:5.76417\teval-rmse:5.71798\ttrain-my-error:0\teval-my-error:0\n",
            "[10]\ttrain-rmse:6.0171\teval-rmse:5.93712\ttrain-my-error:0\teval-my-error:0\n",
            "Stopping. Best iteration:\n",
            "[5]\ttrain-rmse:3.96515\teval-rmse:3.9293\ttrain-my-error:0.001228\teval-my-error:0\n",
            "\n",
            "best_score:        0.0\n",
            "best_iteration:    5\n",
            "best_ntree_limit:  6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "61NenBG_nAZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b6e5d766-7a89-4bbc-8b3d-6646a123b134"
      },
      "cell_type": "code",
      "source": [
        "# Case 2: Default objective function, but user feval\n",
        "bst2 = xgb.train(params=param, dtrain=dtrain, num_boost_round=num_round, evals=watchlist, feval=evalerror, early_stopping_rounds=5)\n",
        "print(\"best_score:       \", bst2.best_score)\n",
        "print(\"best_iteration:   \", bst2.best_iteration)\n",
        "print(\"best_ntree_limit: \", bst2.best_ntree_limit)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-rmse:0.208674\teval-rmse:0.200713\ttrain-my-error:0.517887\teval-my-error:0.518312\n",
            "Multiple eval metrics have been passed: 'eval-my-error' will be used for early stopping.\n",
            "\n",
            "Will train until eval-my-error hasn't improved in 5 rounds.\n",
            "[1]\ttrain-rmse:0.12273\teval-rmse:0.127662\ttrain-my-error:0.517887\teval-my-error:0.518312\n",
            "[2]\ttrain-rmse:0.094829\teval-rmse:0.091932\ttrain-my-error:0.209888\teval-my-error:0.199255\n",
            "[3]\ttrain-rmse:0.07799\teval-rmse:0.073037\ttrain-my-error:0.453094\teval-my-error:0.45748\n",
            "[4]\ttrain-rmse:0.070741\teval-rmse:0.069815\ttrain-my-error:0.419622\teval-my-error:0.431409\n",
            "[5]\ttrain-rmse:0.06459\teval-rmse:0.060638\ttrain-my-error:0.3883\teval-my-error:0.399131\n",
            "[6]\ttrain-rmse:0.059991\teval-rmse:0.055395\ttrain-my-error:0.400123\teval-my-error:0.410925\n",
            "[7]\ttrain-rmse:0.057305\teval-rmse:0.052123\ttrain-my-error:0.400123\teval-my-error:0.410925\n",
            "Stopping. Best iteration:\n",
            "[2]\ttrain-rmse:0.094829\teval-rmse:0.091932\ttrain-my-error:0.209888\teval-my-error:0.199255\n",
            "\n",
            "best_score:        0.199255\n",
            "best_iteration:    2\n",
            "best_ntree_limit:  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17Yg7uDGnpms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "afa748d5-40f0-4242-bd34-dc6441cb794f"
      },
      "cell_type": "code",
      "source": [
        "# Case 3: User objective function, but default feval\n",
        "bst3 = xgb.train(params=param, dtrain=dtrain, num_boost_round=num_round, evals=watchlist, obj=logregobj, early_stopping_rounds=5)\n",
        "print(\"best_score:       \", bst3.best_score)\n",
        "print(\"best_iteration:   \", bst3.best_iteration)\n",
        "print(\"best_ntree_limit: \", bst3.best_ntree_limit)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-rmse:1.59597\teval-rmse:1.59229\n",
            "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
            "\n",
            "Will train until eval-rmse hasn't improved in 5 rounds.\n",
            "[1]\ttrain-rmse:2.40977\teval-rmse:2.40519\n",
            "[2]\ttrain-rmse:2.87459\teval-rmse:2.88253\n",
            "[3]\ttrain-rmse:3.63621\teval-rmse:3.62808\n",
            "[4]\ttrain-rmse:3.83893\teval-rmse:3.80794\n",
            "[5]\ttrain-rmse:3.96515\teval-rmse:3.9293\n",
            "Stopping. Best iteration:\n",
            "[0]\ttrain-rmse:1.59597\teval-rmse:1.59229\n",
            "\n",
            "best_score:        1.592294\n",
            "best_iteration:    0\n",
            "best_ntree_limit:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HzhoJUEan7h0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "fd8579bb-13f4-428c-8317-76bb05b87072"
      },
      "cell_type": "code",
      "source": [
        "# Case 4: Default objective function, default feval\n",
        "bst3 = xgb.train(params=param, dtrain=dtrain, num_boost_round=num_round, evals=watchlist, early_stopping_rounds=5, verbose_eval=10)\n",
        "print(\"best_score:       \", bst3.best_score)\n",
        "print(\"best_iteration:   \", bst3.best_iteration)\n",
        "print(\"best_ntree_limit: \", bst3.best_ntree_limit)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-rmse:0.208674\teval-rmse:0.200713\n",
            "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
            "\n",
            "Will train until eval-rmse hasn't improved in 5 rounds.\n",
            "[10]\ttrain-rmse:0.04218\teval-rmse:0.037257\n",
            "[20]\ttrain-rmse:0.027572\teval-rmse:0.018735\n",
            "[30]\ttrain-rmse:0.016569\teval-rmse:0.012981\n",
            "[40]\ttrain-rmse:0.014828\teval-rmse:0.010438\n",
            "[50]\ttrain-rmse:0.0133\teval-rmse:0.008507\n",
            "Stopping. Best iteration:\n",
            "[53]\ttrain-rmse:0.012907\teval-rmse:0.008088\n",
            "\n",
            "best_score:        0.008088\n",
            "best_iteration:    53\n",
            "best_ntree_limit:  54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eqj2Fl0DoDYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}